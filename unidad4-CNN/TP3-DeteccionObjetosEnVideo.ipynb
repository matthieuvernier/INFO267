{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from IPython.display import clear_output, display\n",
    "import ipywidgets as widgets\n",
    "import PIL.Image\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from models import Darknet\n",
    "from utils.utils import non_max_suppression\n",
    "from utils import *\n",
    "\n",
    "classes = utils.load_classes('config/coco.names')\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mod(4, skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d34cc699095942c19b8f029ee5c555e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', layout=\"Layout(height='360px', width='360px')\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
     ]
    }
   ],
   "source": [
    "cuda = False\n",
    "# Set up model\n",
    "model = Darknet('config/yolov3.cfg', img_size=416)\n",
    "model.load_weights('weights/yolov3.weights')\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "\n",
    "model.eval() # Set in evaluation mode\n",
    "\n",
    "videopath = 'Amsterdam_drive_small_crop.mp4'\n",
    "vid = cv2.VideoCapture(videopath)\n",
    "out = widgets.Image(layout=widgets.Layout(height='360px', width='360px'))\n",
    "display(out)\n",
    "\n",
    "skip, nframe = 2, -1\n",
    "try:\n",
    "    while True:\n",
    "        # Get and prepare frame\n",
    "        ret, frame = vid.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        nframe += 1\n",
    "        if not np.mod(nframe, skip) == 0:\n",
    "            continue\n",
    "        \n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)        \n",
    "        input_imgs = torch.from_numpy(frame/255.).unsqueeze(0).type('torch.FloatTensor')\n",
    "        input_imgs = torch.transpose(input_imgs, 1, 3)\n",
    "        input_imgs = torch.transpose(input_imgs, 2, 3)\n",
    "        if cuda: \n",
    "            input_imgs = input_imgs.cuda()\n",
    "        # Get detections\n",
    "        with torch.no_grad():\n",
    "            detections = model(input_imgs)\n",
    "            detections = non_max_suppression(detections, len(classes), 0.7, 0.4)\n",
    "        detections = detections[0]\n",
    "         # Draw bounding boxes and labels of detections\n",
    "        if detections is not None:\n",
    "            for x1, y1, x2, y2, conf, cls_conf, cls_pred in detections:\n",
    "                # Draw detections on the frame\n",
    "                color = colors[int(cls_pred)]\n",
    "                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n",
    "                cv2.putText(frame, classes[int(cls_pred)], \n",
    "                            (int(x1)-10, int(y1)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "        # Update image widget\n",
    "        f = BytesIO() \n",
    "        PIL.Image.fromarray(frame).save(f, 'JPEG')\n",
    "        out.value = f.getvalue()\n",
    "        #cv2.waitKey(10)\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    vid.release()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
